{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5fcdc2ec6892008f3bd9b93e5313873ef664f4d44edf4818986e0696990c8c99"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import os\n",
    "import shutil\n",
    "from cv2 import *\n",
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), np.uint8)\n",
    "train_path = 'chest_xray/train/'\n",
    "new_train_path = 'New Images/Train'\n",
    "for files in os.listdir(train_path):\n",
    "\n",
    "    new_train_path2 = os.path.join(new_train_path,files)\n",
    "\n",
    "    for f in os.listdir(train_path+files):\n",
    "\n",
    "        img_path=os.path.join(train_path+files,f)\n",
    "        norm=imread(img_path)\n",
    "        norm=cvtColor(norm,COLOR_BGR2GRAY)\n",
    "        th1=equalizeHist(norm)\n",
    "        eroded = cv2.erode(th1, kernel)\n",
    "        dilate = cv2.dilate(eroded,kernel)\n",
    "        eroded2 = cv2.erode(dilate,kernel)\n",
    "\n",
    "        new_train_path3 = os.path.join(new_train_path2,f)\n",
    "\n",
    "        imwrite(new_train_path3,eroded2)\n",
    "\n",
    "test_path = 'chest_xray/test/'\n",
    "new_test_path = 'New Images/Test'\n",
    "\n",
    "for files in os.listdir(test_path):\n",
    "\n",
    "    new_test_path2 = os.path.join(new_test_path,files)\n",
    "\n",
    "    for f in os.listdir(test_path+files):\n",
    "\n",
    "        img_path=os.path.join(test_path+files,f)\n",
    "\n",
    "        norm=imread(img_path)\n",
    "        norm=cvtColor(norm,COLOR_BGR2GRAY)\n",
    "        th1 = equalizeHist(norm)\n",
    "        eroded = cv2.erode(th1, kernel)\n",
    "        dilate = cv2.dilate(eroded, kernel)\n",
    "        eroded2 = cv2.erode(dilate, kernel)\n",
    "\n",
    "        new_test_path3 = os.path.join(new_test_path2,f)\n",
    "\n",
    "        imwrite(new_test_path3, eroded2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 6581 images belonging to 2 classes.\nFound 624 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "IMG_SIZE = 300\n",
    "\n",
    "TRAINING_DIR = \"New Images/Train\"\n",
    "training_datagen = ImageDataGenerator(rescale = 1/255 ,\n",
    "                                  #     rotation_range=15,\n",
    "                                  # height_shift_range=0.2,\n",
    "                                  # width_shift_range=0.2,\n",
    "                                  # shear_range=0.2,\n",
    "                                  zoom_range=0.3,\n",
    "                                  vertical_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "train_generator = training_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                       target_size=(IMG_SIZE,IMG_SIZE) ,class_mode='binary',\n",
    "                                                       batch_size=64,shuffle=True )\n",
    "\n",
    "\n",
    "TEST_DIR = \"New Images/Test\"\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR,target_size=(IMG_SIZE,IMG_SIZE), class_mode='binary',\n",
    "                                                  batch_size=64,\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = tf.keras.applications.ResNet50V2(include_top=False,weights='imagenet',input_shape=(IMG_SIZE,IMG_SIZE,3))\n",
    "feature_extractor.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50v2 (Functional)      (None, 10, 10, 2048)      23564800  \n_________________________________________________________________\nflatten (Flatten)            (None, 204800)            0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               26214528  \n_________________________________________________________________\ndropout (Dropout)            (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               33024     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 49,878,401\nTrainable params: 26,313,601\nNon-trainable params: 23,564,800\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    feature_extractor,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/20\n103/103 [==============================] - 162s 2s/step - loss: 0.1246 - accuracy: 0.9546 - precision: 0.9650 - recall: 0.9578 - val_loss: 0.1022 - val_accuracy: 0.9615 - val_precision: 0.9621 - val_recall: 0.9769\nEpoch 2/20\n103/103 [==============================] - 155s 2s/step - loss: 0.1310 - accuracy: 0.9511 - precision: 0.9614 - recall: 0.9554 - val_loss: 0.1201 - val_accuracy: 0.9567 - val_precision: 0.9595 - val_recall: 0.9718\nEpoch 3/20\n103/103 [==============================] - 157s 2s/step - loss: 0.1138 - accuracy: 0.9591 - precision: 0.9696 - recall: 0.9609 - val_loss: 0.0975 - val_accuracy: 0.9728 - val_precision: 0.9722 - val_recall: 0.9846\nEpoch 4/20\n103/103 [==============================] - 156s 2s/step - loss: 0.1062 - accuracy: 0.9623 - precision: 0.9720 - recall: 0.9639 - val_loss: 0.1121 - val_accuracy: 0.9615 - val_precision: 0.9716 - val_recall: 0.9667\nEpoch 5/20\n103/103 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.9638 - precision: 0.9708 - recall: 0.9678\nEpoch 00005: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n103/103 [==============================] - 155s 2s/step - loss: 0.0950 - accuracy: 0.9638 - precision: 0.9708 - recall: 0.9678 - val_loss: 0.1187 - val_accuracy: 0.9599 - val_precision: 0.9841 - val_recall: 0.9513\nEpoch 6/20\n103/103 [==============================] - 157s 2s/step - loss: 0.0921 - accuracy: 0.9649 - precision: 0.9748 - recall: 0.9655 - val_loss: 0.1183 - val_accuracy: 0.9535 - val_precision: 0.9640 - val_recall: 0.9615\nEpoch 7/20\n103/103 [==============================] - 157s 2s/step - loss: 0.0764 - accuracy: 0.9714 - precision: 0.9780 - recall: 0.9735 - val_loss: 0.1150 - val_accuracy: 0.9599 - val_precision: 0.9716 - val_recall: 0.9641\nEpoch 8/20\n103/103 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9739 - precision: 0.9808 - recall: 0.9748\nEpoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n103/103 [==============================] - 154s 1s/step - loss: 0.0740 - accuracy: 0.9739 - precision: 0.9808 - recall: 0.9748 - val_loss: 0.1115 - val_accuracy: 0.9599 - val_precision: 0.9668 - val_recall: 0.9692\nEpoch 9/20\n103/103 [==============================] - 156s 2s/step - loss: 0.0735 - accuracy: 0.9748 - precision: 0.9804 - recall: 0.9768 - val_loss: 0.1116 - val_accuracy: 0.9615 - val_precision: 0.9692 - val_recall: 0.9692\nEpoch 10/20\n103/103 [==============================] - 156s 2s/step - loss: 0.0710 - accuracy: 0.9731 - precision: 0.9810 - recall: 0.9732 - val_loss: 0.1118 - val_accuracy: 0.9615 - val_precision: 0.9692 - val_recall: 0.9692\nEpoch 11/20\n103/103 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.9733 - precision: 0.9788 - recall: 0.9758\nEpoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n103/103 [==============================] - 157s 2s/step - loss: 0.0740 - accuracy: 0.9733 - precision: 0.9788 - recall: 0.9758 - val_loss: 0.1116 - val_accuracy: 0.9599 - val_precision: 0.9692 - val_recall: 0.9667\nEpoch 12/20\n103/103 [==============================] - 156s 2s/step - loss: 0.0649 - accuracy: 0.9784 - precision: 0.9865 - recall: 0.9768 - val_loss: 0.1115 - val_accuracy: 0.9599 - val_precision: 0.9692 - val_recall: 0.9667\n"
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self,epoch,logs={}):\n",
    "    if(logs['accuracy']>=0.975):\n",
    "      self.model.stop_training=True\n",
    "\n",
    "callbacks=myCallback()\n",
    "METRICS = [\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')]\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='best_weights.hdf5', save_best_only=True, save_weights_only=True)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=2, mode='max')\n",
    "\n",
    "# early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3, mode='min')\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001),loss='binary_crossentropy',metrics=METRICS )\n",
    "\n",
    "history = model.fit(train_generator , epochs=20 , callbacks=[callbacks,checkpoint,lr_reduce], validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10/10 [==============================] - 5s 509ms/step - loss: 0.1115 - accuracy: 0.9599 - precision: 0.9692 - recall: 0.9667\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.11149944365024567,\n 0.9599359035491943,\n 0.9691516757011414,\n 0.9666666388511658]"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "model.evaluate(test_generator, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('model_with_975_early_stopping.h5')"
   ]
  }
 ]
}